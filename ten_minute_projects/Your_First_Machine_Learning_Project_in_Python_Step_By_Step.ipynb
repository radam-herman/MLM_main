{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your First Machine Learning Project in Python Step-By-Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/machine-learning-in-python-step-by-step/\n",
    "by Jason Brownlee on February 10, 2019 in Python Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an overview of what we are going to cover:\n",
    "\n",
    "-- Installing the Python and SciPy platform.\n",
    "-- Loading the dataset.\n",
    "-- Summarizing the dataset.\n",
    "-- Visualizing the dataset.\n",
    "-- Evaluating some algorithms.\n",
    "-- Making some predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 5 key libraries that you will need to install. Below is a list of the Python SciPy libraries required for this tutorial:\n",
    "\n",
    "scipy\n",
    "numpy\n",
    "matplotlib\n",
    "pandas\n",
    "sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Start Python and Check Versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open a command line and start the python interpreter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can skip this if using Jupyter Notebook (JNB)\n",
    "# JNB runs Python \n",
    "# python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the versions of libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.7.3 (default, Mar 27 2019, 16:54:48) \n",
      "[Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "scipy: 1.3.0\n",
      "numpy: 1.16.4\n",
      "matplotlib: 3.1.0\n",
      "pandas: 0.24.2\n",
      "sklearn: 0.21.2\n"
     ]
    }
   ],
   "source": [
    "# Check the versions of libraries\n",
    " \n",
    "# Python version\n",
    "import sys\n",
    "print('Python: {}'.format(sys.version))\n",
    "# scipy\n",
    "import scipy\n",
    "print('scipy: {}'.format(scipy.__version__))\n",
    "# numpy\n",
    "import numpy\n",
    "print('numpy: {}'.format(numpy.__version__))\n",
    "# matplotlib\n",
    "import matplotlib\n",
    "print('matplotlib: {}'.format(matplotlib.__version__))\n",
    "# pandas\n",
    "import pandas\n",
    "print('pandas: {}'.format(pandas.__version__))\n",
    "# scikit-learn\n",
    "import sklearn\n",
    "print('sklearn: {}'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  -- Compare to Jason's output\n",
    "  -- Ideally, your versions should match or be more recent.\n",
    "Python: 3.6.8 (default, Dec 30 2018, 13:01:55) \n",
    "[GCC 4.2.1 Compatible Apple LLVM 9.1.0 (clang-902.0.39.2)]\n",
    "scipy: 1.1.0\n",
    "numpy: 1.15.4\n",
    "matplotlib: 3.0.2\n",
    "pandas: 0.23.4\n",
    "sklearn: 0.20.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using the iris flowers dataset\n",
    "You can learn more about this dataset on Wikipedia - https://en.wikipedia.org/wiki/Iris_flower_data_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using pandas to load the data. We will also use pandas next\n",
    "to explore the data both with descriptive statistics and data visualization.\n",
    "\n",
    "Note that we are specifying the names of each column when loading\n",
    "the data. This will help later when we explore the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv\"\n",
    "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']\n",
    "dataset = pandas.read_csv(url, names=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Summarize the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we are going to take a look at the data a few different ways:\n",
    "1 - Dimensions of the dataset.\n",
    "2 - Peek at the data itself.\n",
    "3 - Statistical summary of all attributes.\n",
    "4 - Breakdown of the data by the class variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Dimensions of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- output\n",
    "(150, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Peek at the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head\n",
    "print(dataset.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "should resemble...\n",
    "    sepal-length  sepal-width  petal-length  petal-width        class\n",
    "0            5.1          3.5           1.4          0.2  Iris-setosa\n",
    "1            4.9          3.0           1.4          0.2  Iris-setosa\n",
    "2            4.7          3.2           1.3          0.2  Iris-setosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Statistical Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptions\n",
    "print(dataset.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "should resemble...\n",
    "       sepal-length  sepal-width  petal-length  petal-width\n",
    "count    150.000000   150.000000    150.000000   150.000000\n",
    "mean       5.843333     3.054000      3.758667     1.198667\n",
    "std        0.828066     0.433594      1.764420     0.763161\n",
    "min        4.300000     2.000000      1.000000     0.100000\n",
    "25%        5.100000     2.800000      1.600000     0.300000\n",
    "50%        5.800000     3.000000      4.350000     1.300000\n",
    "75%        6.400000     3.300000      5.100000     1.800000\n",
    "max        7.900000     4.400000      6.900000     2.500000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4 Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class distribution\n",
    "print(dataset.groupby('class').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "should resemble...\n",
    "class\n",
    "Iris-setosa        50\n",
    "Iris-versicolor    50\n",
    "Iris-virginica     50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "will look at two types of plots:\n",
    "\n",
    "1 -- Univariate plots to better understand each attribute.\n",
    "2 -- Multivariate plots to better understand the relationships between attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1 Univariate Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box and whisker plots\n",
    "dataset.plot(kind='box', subplots=True, layout=(2,2), sharex=False, sharey=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograms\n",
    "dataset.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2 Multivariate Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot matrix\n",
    "scatter_matrix(dataset)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the diagonal grouping of some pairs of attributes. \n",
    "This suggests a high correlation and a predictable relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluate Some Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what we are going to cover in this step:\n",
    "\n",
    "1 -- Separate out a validation dataset.\n",
    "2 -- Set-up the test harness to use 10-fold cross validation.\n",
    "3 -- Build 5 different models to predict species from flower measurements\n",
    "4 -- Select the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1 Create a Validation Dataset\n",
    "\n",
    "Later, we will use statistical methods to estimate the accuracy of the models\n",
    "that we create on unseen data. We also want a more concrete estimate of the accuracy\n",
    "of the best model on unseen data by evaluating it on actual unseen data.\n",
    "\n",
    "we are going to hold back some data that the algorithms will not get to see and \n",
    "we will use this data to get a second and independent idea of how accurate the best model\n",
    "might actually be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split-out validation dataset\n",
    "array = dataset.values\n",
    "X = array[:,0:4]\n",
    "Y = array[:,4]\n",
    "validation_size = 0.20\n",
    "seed = 7\n",
    "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have training data in the X_train and Y_train for preparing models and a X_validation \n",
    "and Y_validation sets that we can use later.\n",
    "\n",
    "Notice that we used a python slice to select the columns in the NumPy array. If this is new to you, you might want to check-out this post:\n",
    "\n",
    "How to Index, Slice and Reshape NumPy Arrays for Machine Learning in Python\n",
    "https://machinelearningmastery.com/index-slice-reshape-numpy-arrays-machine-learning-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2 Test Harness\n",
    "\n",
    "We will use 10-fold cross validation to estimate accuracy.\n",
    "\n",
    "This will split our dataset into 10 parts, train on 9 and test on 1 \n",
    "and repeat for all combinations of train-test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test options and evaluation metric\n",
    "seed = 7\n",
    "scoring = 'accuracy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.3 Build Models\n",
    "\n",
    "We don’t know which algorithms would be good on this problem or what configurations to use.\n",
    "We get an idea from the plots that some of the classes are partially linearly separable \n",
    "in some dimensions, so we are expecting generally good results.\n",
    "\n",
    "Let’s evaluate 6 different algorithms:\n",
    "\n",
    "- Logistic Regression (LR)\n",
    "- Linear Discriminant Analysis (LDA)\n",
    "- K-Nearest Neighbors (KNN).\n",
    "- Classification and Regression Trees (CART).\n",
    "- Gaussian Naive Bayes (NB).\n",
    "- Support Vector Machines (SVM).\n",
    "\n",
    "This is a good mixture of simple linear (LR and LDA), \n",
    "nonlinear (KNN, CART, NB and SVM) algorithms. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot Check Algorithms\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC(gamma='auto')))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "\tkfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "\tcv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "\tresults.append(cv_results)\n",
    "\tnames.append(name)\n",
    "\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "\tprint(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.4 Select Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   output fm above --\n",
    "LR: 0.966667 (0.040825)\n",
    "LDA: 0.975000 (0.038188)\n",
    "KNN: 0.983333 (0.033333)\n",
    "CART: 0.975000 (0.038188)\n",
    "NB: 0.975000 (0.053359)\n",
    "SVM: 0.991667 (0.025000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Make Predictions\n",
    "\n",
    "We can run the KNN model directly on the validation set and summarize \n",
    "the results as a final accuracy score, a confusion matrix and a classification report.\n",
    "http://machinelearningmastery.com/confusion-matrix-machine-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on validation dataset\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, Y_train)\n",
    "predictions = knn.predict(X_validation)\n",
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "should resemble...\n",
    "0.9\n",
    "[[ 7  0  0]\n",
    " [ 0 11  1]\n",
    " [ 0  2  9]]\n",
    "                 precision    recall  f1-score   support\n",
    "\n",
    "    Iris-setosa       1.00      1.00      1.00         7\n",
    "Iris-versicolor       0.85      0.92      0.88        12\n",
    " Iris-virginica       0.90      0.82      0.86        11\n",
    "\n",
    "      micro avg       0.90      0.90      0.90        30\n",
    "      macro avg       0.92      0.91      0.91        30\n",
    "   weighted avg       0.90      0.90      0.90        30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to Make Predictions with scikit-learn\n",
    "\n",
    "https://machinelearningmastery.com/make-predictions-scikit-learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
